{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dce8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Recreate val split, run inference, compute per-class metrics ===\n",
    "# Edit these:\n",
    "DATA_FILE = \"C:/Users/chris/Desktop/Documents/Code/MultimodalDataChallenge2025/metadata.csv\"\n",
    "IMAGE_DIR = \"A:/FungiImages/FungiImages\" # root containing fungi_train/*\n",
    "CKPT_DIR  = \"C:/Users/chris/Desktop/Documents/Code/MultimodalDataChallenge2025/checkpoints/\" # where best_accuracy.pth lives\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "# --- Transforms (valid) ---\n",
    "def get_valid_tf():\n",
    "    w, h = 224, 224\n",
    "    return Compose([Resize(w, h),\n",
    "                    Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "                    ToTensorV2()])\n",
    "\n",
    "# --- Dataset ---\n",
    "class FungiDataset(Dataset):\n",
    "    def __init__(self, df, root, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root, self.t = root, transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        fp = self.df[\"filename_index\"].iloc[i].strip()\n",
    "        y  = int(self.df[\"taxonID_index\"].iloc[i])  # <- restore label extraction\n",
    "        path = os.path.join(self.root, fp)\n",
    "        #print(f\"[DBG] idx={i} -> {path}\")\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Image not found: {path}. Check IMAGE_DIR.\")\n",
    "\n",
    "        if self.t is None:\n",
    "            raise RuntimeError(\"Transform is None (get_valid_tf() not applied).\")\n",
    "\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                im = np.array(img.convert(\"RGB\"))\n",
    "            im = self.t(image=im)[\"image\"]\n",
    "            return im, y, fp\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"__getitem__ failed for {path}: {type(e).__name__}: {e}\")\n",
    "\n",
    "\n",
    "# --- Recreate EXACT split ---\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "df[\"filename_index\"] = df[\"filename_index\"].astype(str).str.strip()\n",
    "train_df_all = df[df[\"filename_index\"].str.startswith(\"fungi_train\")].dropna(subset=[\"taxonID_index\"]).copy()\n",
    "train_df_all[\"taxonID_index\"] = train_df_all[\"taxonID_index\"].astype(int)\n",
    "\n",
    "train_df, val_df = train_test_split(train_df_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Model ---\n",
    "num_classes = train_df_all[\"taxonID_index\"].nunique()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(model.classifier[1].in_features, num_classes)\n",
    ")\n",
    "state_path = os.path.join(CKPT_DIR, \"best_accuracy.pth\")\n",
    "model.load_state_dict(torch.load(state_path, map_location=device))\n",
    "model.to(device).eval()\n",
    "\n",
    "# --- Inference on VAL ---\n",
    "val_ds = FungiDataset(val_df, IMAGE_DIR, transform=get_valid_tf())\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d463097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does a single sample load?\n",
    "x0, y0, f0 = val_ds[0]; print(f0, x0.shape)\n",
    "\n",
    "# does one batch load?\n",
    "tmp_loader = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=0)\n",
    "xb, yb, fb = next(iter(tmp_loader)); print(xb.shape, len(fb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "y_true, y_pred, names = [], [], []\n",
    "with torch.no_grad():\n",
    "    for x, y, fn in tqdm(val_loader, desc=\"Validating\", unit=\"batch\"):\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().numpy()\n",
    "        y_pred.extend(preds.tolist())\n",
    "        y_true.extend(y.numpy().tolist())\n",
    "        names.extend(fn)\n",
    "\n",
    "y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
    "\n",
    "# --- Metrics ---\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "# ensure we include all classes (even if some are missing in y_pred)\n",
    "labels_sorted = sorted(pd.unique(train_df_all[\"taxonID_index\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e291aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=labels_sorted,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "rep_df = pd.DataFrame(rep).transpose()\n",
    "\n",
    "# select ROWS whose index is digits (per-class rows)\n",
    "per_class = rep_df.loc[rep_df.index.map(str).str.fullmatch(r\"\\d+\")].copy()\n",
    "per_class.index = per_class.index.astype(int)\n",
    "\n",
    "# reindex to include every class in labels_sorted (missing rows become NaN)\n",
    "per_class = per_class.reindex(labels_sorted)\n",
    "\n",
    "per_class = per_class.rename(columns={\"precision\":\"prec\",\"recall\":\"rec\",\"f1-score\":\"f1\",\"support\":\"n\"})\n",
    "\n",
    "\n",
    "labels_sorted = sorted(per_class.index.unique())\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_sorted)\n",
    "diag = np.diag(cm).astype(float)\n",
    "row_sum = cm.sum(axis=1).astype(float)\n",
    "per_class[\"accuracy\"] = np.divide(diag, row_sum, out=np.zeros_like(diag), where=row_sum>0)\n",
    "# Misclassifications list\n",
    "mis = pd.DataFrame({\n",
    "    \"filename_index\": names,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred\n",
    "})\n",
    "mis = mis[mis[\"y_true\"] != mis[\"y_pred\"]]\n",
    "\n",
    "# --- Save ---\n",
    "out = Path(CKPT_DIR)\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "per_class.to_csv(out/\"val_per_class_metrics.csv\", index_label=\"class_index\")\n",
    "pd.DataFrame(cm, index=labels_sorted, columns=labels_sorted).to_csv(out/\"val_confusion_matrix.csv\")\n",
    "rep_df.loc[[\"accuracy\",\"macro avg\",\"weighted avg\"]].to_csv(out/\"val_overall_metrics.csv\")\n",
    "mis.to_csv(out/\"val_misclassified.csv\", index=False)\n",
    "\n",
    "print(f\"VAL accuracy: {acc:.4f}\")\n",
    "print(f\"Saved: {out/'val_per_class_metrics.csv'}, {out/'val_confusion_matrix.csv'}, {out/'val_overall_metrics.csv'}, {out/'val_misclassified.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
