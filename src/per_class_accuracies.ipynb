{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5dce8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# === Recreate val split, run inference, compute per-class metrics ===\n",
    "# Edit these:\n",
    "DATA_FILE = \"C:/Users/chris/Desktop/Documents/Code/MultimodalDataChallenge2025/metadata.csv\"\n",
    "IMAGE_DIR = \"A:/FungiImages/FungiImages\" # root containing fungi_train/*\n",
    "CKPT_DIR  = \"C:/Users/chris/Desktop/Documents/Code/MultimodalDataChallenge2025/checkpoints/\" # where best_accuracy.pth lives\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import Compose, Normalize, Resize\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "# --- Transforms (valid) ---\n",
    "def get_valid_tf():\n",
    "    w, h = 224, 224\n",
    "    return Compose([Resize(w, h),\n",
    "                    Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "                    ToTensorV2()])\n",
    "\n",
    "# --- Dataset ---\n",
    "class FungiDataset(Dataset):\n",
    "    def __init__(self, df, root, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root, self.t = root, transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        fp = self.df[\"filename_index\"].iloc[i].strip()\n",
    "        y  = int(self.df[\"taxonID_index\"].iloc[i])  # <- restore label extraction\n",
    "        path = os.path.join(self.root, fp)\n",
    "        #print(f\"[DBG] idx={i} -> {path}\")\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Image not found: {path}. Check IMAGE_DIR.\")\n",
    "\n",
    "        if self.t is None:\n",
    "            raise RuntimeError(\"Transform is None (get_valid_tf() not applied).\")\n",
    "\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                im = np.array(img.convert(\"RGB\"))\n",
    "            im = self.t(image=im)[\"image\"]\n",
    "            return im, y, fp\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"__getitem__ failed for {path}: {type(e).__name__}: {e}\")\n",
    "\n",
    "\n",
    "# --- Recreate EXACT split ---\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "df[\"filename_index\"] = df[\"filename_index\"].astype(str).str.strip()\n",
    "train_df_all = df[df[\"filename_index\"].str.startswith(\"fungi_train\")].dropna(subset=[\"taxonID_index\"]).copy()\n",
    "train_df_all[\"taxonID_index\"] = train_df_all[\"taxonID_index\"].astype(int)\n",
    "\n",
    "train_df, val_df = train_test_split(train_df_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Model ---\n",
    "num_classes = train_df_all[\"taxonID_index\"].nunique()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(model.classifier[1].in_features, num_classes)\n",
    ")\n",
    "state_path = os.path.join(CKPT_DIR, \"best_accuracy.pth\")\n",
    "model.load_state_dict(torch.load(state_path, map_location=device))\n",
    "model.to(device).eval()\n",
    "\n",
    "# --- Inference on VAL ---\n",
    "val_ds = FungiDataset(val_df, IMAGE_DIR, transform=get_valid_tf())\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d463097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fungi_train004036.jpg torch.Size([3, 224, 224])\n",
      "torch.Size([4, 3, 224, 224]) 4\n"
     ]
    }
   ],
   "source": [
    "# does a single sample load?\n",
    "x0, y0, f0 = val_ds[0]; print(f0, x0.shape)\n",
    "\n",
    "# does one batch load?\n",
    "tmp_loader = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=0)\n",
    "xb, yb, fb = next(iter(tmp_loader)); print(xb.shape, len(fb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   9%|â–‰         | 15/162 [01:20<13:06,  5.35s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early after 16 batches (9.9% of data).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "y_true, y_pred, names = [], [], []\n",
    "with torch.no_grad():\n",
    "    total_batches = len(val_loader)\n",
    "    limit_batches = max(1, int(total_batches * 0.1))  # 10% of batches\n",
    "\n",
    "    for batch_idx, (x, y, fn) in enumerate(tqdm(val_loader, desc=\"Validating\", unit=\"batch\")):\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().numpy()\n",
    "        y_pred.extend(preds.tolist())\n",
    "        y_true.extend(y.numpy().tolist())\n",
    "        names.extend(fn)\n",
    "\n",
    "        # if batch_idx + 1 >= limit_batches:\n",
    "        #     print(f\"Stopping early after {limit_batches} batches ({100*limit_batches/total_batches:.1f}% of data).\")\n",
    "        #     break\n",
    "\n",
    "y_true = np.array(y_true); y_pred = np.array(y_pred)\n",
    "\n",
    "# --- Metrics ---\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "# ensure we include all classes (even if some are missing in y_pred)\n",
    "labels_sorted = sorted(pd.unique(train_df_all[\"taxonID_index\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e291aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL accuracy: 0.5352\n",
      "Saved: C:\\Users\\chris\\Desktop\\Documents\\Code\\MultimodalDataChallenge2025\\checkpoints\\val_per_class_metrics.csv, C:\\Users\\chris\\Desktop\\Documents\\Code\\MultimodalDataChallenge2025\\checkpoints\\val_confusion_matrix.csv, C:\\Users\\chris\\Desktop\\Documents\\Code\\MultimodalDataChallenge2025\\checkpoints\\val_overall_metrics.csv, C:\\Users\\chris\\Desktop\\Documents\\Code\\MultimodalDataChallenge2025\\checkpoints\\val_misclassified.csv\n"
     ]
    }
   ],
   "source": [
    "rep = classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=labels_sorted,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "rep_df = pd.DataFrame(rep).transpose()\n",
    "\n",
    "# select ROWS whose index is digits (per-class rows)\n",
    "per_class = rep_df.loc[rep_df.index.map(str).str.fullmatch(r\"\\d+\")].copy()\n",
    "per_class.index = per_class.index.astype(int)\n",
    "\n",
    "# reindex to include every class in labels_sorted (missing rows become NaN)\n",
    "per_class = per_class.reindex(labels_sorted)\n",
    "\n",
    "per_class = per_class.rename(columns={\"precision\":\"prec\",\"recall\":\"rec\",\"f1-score\":\"f1\",\"support\":\"n\"})\n",
    "\n",
    "\n",
    "labels_sorted = sorted(per_class.index.unique())\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_sorted)\n",
    "diag = np.diag(cm).astype(float)\n",
    "row_sum = cm.sum(axis=1).astype(float)\n",
    "per_class[\"accuracy\"] = np.divide(diag, row_sum, out=np.zeros_like(diag), where=row_sum>0)\n",
    "# Misclassifications list\n",
    "mis = pd.DataFrame({\n",
    "    \"filename_index\": names,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred\n",
    "})\n",
    "mis = mis[mis[\"y_true\"] != mis[\"y_pred\"]]\n",
    "\n",
    "# --- Save ---\n",
    "out = Path(CKPT_DIR)\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "per_class.to_csv(out/\"val_per_class_metrics.csv\", index_label=\"class_index\")\n",
    "pd.DataFrame(cm, index=labels_sorted, columns=labels_sorted).to_csv(out/\"val_confusion_matrix.csv\")\n",
    "rep_df.loc[[\"accuracy\",\"macro avg\",\"weighted avg\"]].to_csv(out/\"val_overall_metrics.csv\")\n",
    "mis.to_csv(out/\"val_misclassified.csv\", index=False)\n",
    "\n",
    "print(f\"VAL accuracy: {acc:.4f}\")\n",
    "print(f\"Saved: {out/'val_per_class_metrics.csv'}, {out/'val_confusion_matrix.csv'}, {out/'val_overall_metrics.csv'}, {out/'val_misclassified.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
